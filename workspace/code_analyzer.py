"""
Analizador inteligente de c√≥digo
"""

import ast
import json
import re
import hashlib
from pathlib import Path
from typing import Dict, List, Any, Optional, Set, Tuple
from collections import defaultdict, Counter

from .analysis_cache import AnalysisCache

class CodeAnalyzer:
    """Analizador inteligente de c√≥digo y proyectos"""
    
    def __init__(self, settings, ollama_interface):
        self.settings = settings
        self.ollama_interface = ollama_interface
        self.workspace_dir = settings.workspace_dir
        
        # Initialize intelligent caching system
        self.cache = AnalysisCache(self.workspace_dir)
    
    def analyze_project(self, path: str = '.') -> str:
        """
        Analizar un proyecto completo
        
        Args:
            path: Ruta del proyecto a analizar
        
        Returns:
            An√°lisis completo del proyecto
        """
        try:
            target_path = Path(self.workspace_dir) / path
            
            if not target_path.exists():
                return f"‚ùå El directorio '{path}' no existe"
            
            # Recopilar informaci√≥n del proyecto
            project_info = self._gather_project_info(target_path)
            
            # Generar an√°lisis con LLM
            analysis = self._generate_project_analysis(project_info)
            
            return analysis
            
        except Exception as e:
            return f"‚ùå Error analizando proyecto: {e}"
    
    def analyze_file(self, file_path: str) -> str:
        """
        Analizar un archivo espec√≠fico (con cache inteligente)
        
        Args:
            file_path: Ruta del archivo a analizar
        
        Returns:
            An√°lisis detallado del archivo
        """
        try:
            target_path = Path(self.workspace_dir) / file_path
            
            if not target_path.exists():
                return f"‚ùå El archivo '{file_path}' no existe"
            
            if not target_path.is_file():
                return f"‚ùå '{file_path}' no es un archivo"
            
            # üöÄ OPTIMIZACI√ìN: Usar cache para leer contenido
            content = self.cache.get_file_content(target_path)
            if content is None:
                return f"‚ùå '{file_path}' parece ser un archivo binario o inaccesible"
            
            # üöÄ OPTIMIZACI√ìN: Verificar cache de an√°lisis LLM
            content_hash = hashlib.md5(content.encode()).hexdigest()
            cached_analysis = self.cache.get_llm_analysis(content_hash, 'file_analysis')
            
            if cached_analysis:
                return f"üìã An√°lisis de {file_path} (cached):\n\n{cached_analysis}"
            
            # An√°lisis no cacheado - proceder normalmente
            file_type = self._detect_file_type(target_path)
            analysis = self._analyze_by_type(content, file_path, file_type)
            
            # üöÄ OPTIMIZACI√ìN: Cachear resultado del an√°lisis
            self.cache.cache_llm_analysis(content_hash, 'file_analysis', analysis)
            
            return analysis
            
        except Exception as e:
            return f"‚ùå Error analizando archivo: {e}"
    
    def find_issues(self, path: str = '.') -> str:
        """
        Encontrar problemas potenciales en el c√≥digo (optimizado con cache)
        
        Args:
            path: Ruta a analizar
        
        Returns:
            Lista de problemas encontrados
        """
        try:
            target_path = Path(self.workspace_dir) / path
            issues = []
            
            # üöÄ OPTIMIZACI√ìN: Usar cache de estructura de proyecto
            project_structure = self.cache.get_project_structure()
            
            if project_structure:
                # Usar estructura cacheada
                code_files = [
                    self.workspace_dir / file_info['path'] 
                    for file_info in project_structure['code_files']
                    if str(self.workspace_dir / file_info['path']).startswith(str(target_path))
                ]
            else:
                # Fallback al m√©todo original
                code_files = [
                    file_path for file_path in target_path.rglob('*')
                    if file_path.is_file() and self._is_code_file(file_path)
                ]
            
            # Analizar archivos de c√≥digo encontrados
            for file_path in code_files:
                file_issues = self._find_file_issues(file_path)
                if file_issues:
                    issues.extend(file_issues)
            
            if not issues:
                return "‚úÖ No se encontraron problemas obvios en el c√≥digo"
            
            # Formatear resultados
            result = f"‚ö†Ô∏è Encontrados {len(issues)} problemas potenciales:\n\n"
            
            # Agrupar por tipo
            issues_by_type = defaultdict(list)
            for issue in issues:
                issues_by_type[issue['type']].append(issue)
            
            for issue_type, type_issues in issues_by_type.items():
                result += f"üîç **{issue_type.upper()}**:\n"
                for issue in type_issues[:5]:  # Limitar a 5 por tipo
                    result += f"  ‚Ä¢ {issue['file']}:{issue['line']} - {issue['message']}\n"
                
                if len(type_issues) > 5:
                    result += f"  ... y {len(type_issues) - 5} m√°s\n"
                result += "\n"
            
            return result
            
        except Exception as e:
            return f"‚ùå Error buscando problemas: {e}"
    
    def suggest_improvements(self, file_path: str) -> str:
        """
        Sugerir mejoras para un archivo
        
        Args:
            file_path: Archivo a analizar
        
        Returns:
            Sugerencias de mejora
        """
        try:
            target_path = Path(self.workspace_dir) / file_path
            
            if not target_path.exists():
                return f"‚ùå El archivo '{file_path}' no existe"
            
            # Leer y analizar archivo
            with open(target_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Generar sugerencias con LLM
            suggestions = self._generate_suggestions(content, file_path)
            
            return suggestions
            
        except Exception as e:
            return f"‚ùå Error generando sugerencias: {e}"
    
    def calculate_complexity(self, file_path: str) -> str:
        """
        Calcular complejidad de un archivo Python
        
        Args:
            file_path: Archivo Python a analizar
        
        Returns:
            M√©tricas de complejidad
        """
        try:
            target_path = Path(self.workspace_dir) / file_path
            
            if not target_path.exists():
                return f"‚ùå El archivo '{file_path}' no existe"
            
            if not str(target_path).endswith('.py'):
                return f"‚ùå Solo se puede analizar complejidad de archivos Python"
            
            # üöÄ OPTIMIZACI√ìN: Usar cache para contenido y AST
            content = self.cache.get_file_content(target_path)
            if content is None:
                return f"‚ùå No se pudo leer el archivo '{file_path}'"
            
            # Intentar obtener an√°lisis AST del cache
            ast_analysis = self.cache.get_ast_analysis(target_path, content)
            
            if ast_analysis:
                # Usar datos del cache
                functions_count = len(ast_analysis['functions'])
                classes_count = len(ast_analysis['classes'])
                imports_count = len(ast_analysis['imports'])
                complexity_score = ast_analysis['complexity_score']
                
                # Crear m√©tricas desde el cache
                metrics = {
                    'functions': functions_count,
                    'classes': classes_count, 
                    'imports': imports_count,
                    'complexity': complexity_score,
                    'lines': len(content.splitlines()),
                    'cached': True
                }
            else:
                # Parsear AST (fallback)
                try:
                    tree = ast.parse(content)
                except SyntaxError as e:
                    return f"‚ùå Error de sintaxis en l√≠nea {e.lineno}: {e.msg}"
                
                # Calcular m√©tricas
                metrics = self._calculate_ast_metrics(tree)
                metrics['cached'] = False
            
            # Formatear resultados
            result = f"üìä An√°lisis de complejidad para '{file_path}':\n\n"
            result += f"üìè L√≠neas de c√≥digo: {len(content.split())}\n"
            result += f"üî¢ Funciones: {metrics['functions']}\n"
            result += f"üìö Clases: {metrics['classes']}\n"
            result += f"üì• Imports: {metrics['imports']}\n"
            result += f"üîÑ Complejidad ciclom√°tica promedio: {metrics['avg_complexity']:.1f}\n"
            
            if metrics['max_complexity'] > 10:
                result += f"‚ö†Ô∏è Funci√≥n m√°s compleja: {metrics['max_complexity']} (considerar refactoring)\n"
            
            return result
            
        except Exception as e:
            return f"‚ùå Error calculando complejidad: {e}"
    
    def _gather_project_info(self, project_path: Path) -> Dict[str, Any]:
        """Recopilar informaci√≥n general del proyecto"""
        info = {
            'name': project_path.name,
            'path': str(project_path),
            'files': [],
            'languages': Counter(),
            'structure': {},
            'config_files': [],
            'documentation': [],
            'tests': [],
            'size_info': {'total_files': 0, 'total_size': 0}
        }
        
        for file_path in project_path.rglob('*'):
            if file_path.is_file() and not self._should_ignore_file(file_path):
                # Informaci√≥n b√°sica del archivo
                rel_path = file_path.relative_to(project_path)
                file_info = {
                    'path': str(rel_path),
                    'size': file_path.stat().st_size,
                    'type': self._detect_file_type(file_path)
                }
                
                info['files'].append(file_info)
                info['languages'][file_info['type']] += 1
                info['size_info']['total_files'] += 1
                info['size_info']['total_size'] += file_info['size']
                
                # Categorizar archivos especiales
                if file_info['type'] in ['json', 'yaml', 'toml'] or 'config' in str(rel_path).lower():
                    info['config_files'].append(str(rel_path))
                elif file_info['type'] == 'markdown' or 'readme' in str(rel_path).lower():
                    info['documentation'].append(str(rel_path))
                elif 'test' in str(rel_path).lower():
                    info['tests'].append(str(rel_path))
        
        return info
    
    def _generate_project_analysis(self, project_info: Dict[str, Any]) -> str:
        """Generar an√°lisis del proyecto usando LLM"""
        try:
            # Preparar prompt para LLM
            prompt = f"""Analiza este proyecto de software y proporciona un resumen completo:

INFORMACI√ìN DEL PROYECTO:
- Nombre: {project_info['name']}
- Total de archivos: {project_info['size_info']['total_files']}
- Tama√±o total: {self._format_size(project_info['size_info']['total_size'])}

LENGUAJES/TECNOLOG√çAS:
{self._format_languages(project_info['languages'])}

ARCHIVOS DE CONFIGURACI√ìN:
{', '.join(project_info['config_files'][:5]) if project_info['config_files'] else 'Ninguno'}

DOCUMENTACI√ìN:
{', '.join(project_info['documentation'][:3]) if project_info['documentation'] else 'Ninguna'}

TESTS:
{', '.join(project_info['tests'][:3]) if project_info['tests'] else 'Ninguno'}

ESTRUCTURA PRINCIPAL:
{self._format_main_structure(project_info['files'])}

Por favor proporciona:
1. Tipo de proyecto (web app, CLI, biblioteca, etc.)
2. Tecnolog√≠as principales identificadas
3. Calidad del proyecto (estructura, documentaci√≥n, tests)
4. Posibles mejoras o problemas
5. Sugerencias de desarrollo

Responde de forma concisa y pr√°ctica."""

            messages = [{'role': 'user', 'content': prompt}]
            analysis = self.ollama_interface.chat(messages, self.settings.models['primary'])
            
            if analysis:
                return f"üîç **An√°lisis del proyecto '{project_info['name']}':**\n\n{analysis}"
            else:
                return self._generate_basic_analysis(project_info)
                
        except Exception as e:
            return self._generate_basic_analysis(project_info)
    
    def _generate_basic_analysis(self, project_info: Dict[str, Any]) -> str:
        """Generar an√°lisis b√°sico sin LLM"""
        result = f"üìä **An√°lisis b√°sico del proyecto '{project_info['name']}':**\n\n"
        
        # Estad√≠sticas b√°sicas
        result += f"üìÅ **Estad√≠sticas:**\n"
        result += f"  ‚Ä¢ {project_info['size_info']['total_files']} archivos\n"
        result += f"  ‚Ä¢ {self._format_size(project_info['size_info']['total_size'])} de tama√±o total\n\n"
        
        # Lenguajes
        result += f"üíª **Tecnolog√≠as:**\n"
        for lang, count in project_info['languages'].most_common(5):
            result += f"  ‚Ä¢ {lang}: {count} archivos\n"
        result += "\n"
        
        # Evaluaci√≥n b√°sica
        result += f"‚úÖ **Evaluaci√≥n:**\n"
        
        if project_info['documentation']:
            result += f"  ‚Ä¢ ‚úÖ Tiene documentaci√≥n ({len(project_info['documentation'])} archivos)\n"
        else:
            result += f"  ‚Ä¢ ‚ö†Ô∏è Falta documentaci√≥n\n"
        
        if project_info['tests']:
            result += f"  ‚Ä¢ ‚úÖ Tiene tests ({len(project_info['tests'])} archivos)\n"
        else:
            result += f"  ‚Ä¢ ‚ö†Ô∏è No se encontraron tests\n"
        
        if project_info['config_files']:
            result += f"  ‚Ä¢ ‚úÖ Archivos de configuraci√≥n presentes\n"
        
        return result
    
    def _analyze_by_type(self, content: str, file_path: str, file_type: str) -> str:
        """Analizar archivo seg√∫n su tipo"""
        if file_type == 'python':
            return self._analyze_python_file(content, file_path)
        elif file_type == 'javascript':
            return self._analyze_javascript_file(content, file_path)
        elif file_type == 'json':
            return self._analyze_json_file(content, file_path)
        else:
            return self._analyze_generic_file(content, file_path, file_type)
    
    def _analyze_python_file(self, content: str, file_path: str) -> str:
        """An√°lisis espec√≠fico para archivos Python"""
        try:
            tree = ast.parse(content)
            metrics = self._calculate_ast_metrics(tree)
            
            result = f"üêç **An√°lisis de '{file_path}':**\n\n"
            result += f"üìä **M√©tricas:**\n"
            result += f"  ‚Ä¢ L√≠neas: {len(content.split())}\n"
            result += f"  ‚Ä¢ Funciones: {metrics['functions']}\n"
            result += f"  ‚Ä¢ Clases: {metrics['classes']}\n"
            result += f"  ‚Ä¢ Imports: {metrics['imports']}\n"
            result += f"  ‚Ä¢ Complejidad promedio: {metrics['avg_complexity']:.1f}\n\n"
            
            # Funciones principales
            if metrics['function_names']:
                result += f"üîß **Funciones principales:**\n"
                for func in metrics['function_names'][:5]:
                    result += f"  ‚Ä¢ {func}\n"
                result += "\n"
            
            # Imports
            if metrics['import_names']:
                result += f"üì¶ **Dependencias:**\n"
                for imp in metrics['import_names'][:5]:
                    result += f"  ‚Ä¢ {imp}\n"
                result += "\n"
            
            return result
            
        except SyntaxError as e:
            return f"‚ùå Error de sintaxis en '{file_path}' l√≠nea {e.lineno}: {e.msg}"
        except Exception as e:
            return f"‚ùå Error analizando '{file_path}': {e}"
    
    def _analyze_javascript_file(self, content: str, file_path: str) -> str:
        """An√°lisis b√°sico para archivos JavaScript"""
        lines = content.split('\n')
        
        # An√°lisis b√°sico con regex
        functions = len(re.findall(r'function\s+\w+', content))
        classes = len(re.findall(r'class\s+\w+', content))
        imports = len(re.findall(r'import\s+.*from', content))
        
        result = f"üü® **An√°lisis de '{file_path}':**\n\n"
        result += f"üìä **M√©tricas:**\n"
        result += f"  ‚Ä¢ L√≠neas: {len(lines)}\n"
        result += f"  ‚Ä¢ Funciones: {functions}\n"
        result += f"  ‚Ä¢ Clases: {classes}\n"
        result += f"  ‚Ä¢ Imports: {imports}\n"
        
        return result
    
    def _analyze_json_file(self, content: str, file_path: str) -> str:
        """An√°lisis para archivos JSON"""
        try:
            data = json.loads(content)
            
            result = f"üìã **An√°lisis de '{file_path}':**\n\n"
            result += f"üìä **Estructura:**\n"
            result += f"  ‚Ä¢ Tipo: {type(data).__name__}\n"
            
            if isinstance(data, dict):
                result += f"  ‚Ä¢ Claves principales: {len(data)}\n"
                result += f"  ‚Ä¢ Claves: {', '.join(list(data.keys())[:5])}\n"
            elif isinstance(data, list):
                result += f"  ‚Ä¢ Elementos: {len(data)}\n"
            
            return result
            
        except json.JSONDecodeError as e:
            return f"‚ùå JSON inv√°lido en '{file_path}': {e.msg}"
    
    def _analyze_generic_file(self, content: str, file_path: str, file_type: str) -> str:
        """An√°lisis gen√©rico para otros tipos de archivo"""
        lines = content.split('\n')
        
        result = f"üìÑ **An√°lisis de '{file_path}' ({file_type}):**\n\n"
        result += f"üìä **Estad√≠sticas b√°sicas:**\n"
        result += f"  ‚Ä¢ L√≠neas: {len(lines)}\n"
        result += f"  ‚Ä¢ Caracteres: {len(content)}\n"
        result += f"  ‚Ä¢ Tama√±o: {self._format_size(len(content.encode('utf-8')))}\n"
        
        # L√≠neas no vac√≠as
        non_empty_lines = [line for line in lines if line.strip()]
        result += f"  ‚Ä¢ L√≠neas con contenido: {len(non_empty_lines)}\n"
        
        return result
    
    def _calculate_ast_metrics(self, tree: ast.AST) -> Dict[str, Any]:
        """Calcular m√©tricas del AST de Python"""
        functions = []
        classes = []
        imports = []
        complexities = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                functions.append(node.name)
                complexity = self._calculate_cyclomatic_complexity(node)
                complexities.append(complexity)
            elif isinstance(node, ast.ClassDef):
                classes.append(node.name)
            elif isinstance(node, (ast.Import, ast.ImportFrom)):
                if isinstance(node, ast.Import):
                    imports.extend([alias.name for alias in node.names])
                else:
                    imports.append(node.module or 'relative')
        
        return {
            'functions': len(functions),
            'classes': len(classes),
            'imports': len(imports),
            'function_names': functions,
            'class_names': classes,
            'import_names': imports,
            'avg_complexity': sum(complexities) / len(complexities) if complexities else 0,
            'max_complexity': max(complexities) if complexities else 0
        }
    
    def _calculate_cyclomatic_complexity(self, node: ast.FunctionDef) -> int:
        """Calcular complejidad ciclom√°tica b√°sica"""
        complexity = 1  # Base complexity
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        
        return complexity
    
    def _find_file_issues(self, file_path: Path) -> List[Dict[str, Any]]:
        """Encontrar problemas en un archivo espec√≠fico"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            rel_path = file_path.relative_to(self.workspace_dir)
            
            for i, line in enumerate(lines, 1):
                # Problemas comunes
                if len(line.rstrip()) > 120:
                    issues.append({
                        'type': 'style',
                        'file': str(rel_path),
                        'line': i,
                        'message': 'L√≠nea muy larga (>120 caracteres)'
                    })
                
                if line.rstrip().endswith('  '):
                    issues.append({
                        'type': 'style',
                        'file': str(rel_path),
                        'line': i,
                        'message': 'Espacios al final de l√≠nea'
                    })
                
                if 'TODO' in line or 'FIXME' in line:
                    issues.append({
                        'type': 'todo',
                        'file': str(rel_path),
                        'line': i,
                        'message': 'Comentario TODO/FIXME pendiente'
                    })
                
                if 'print(' in line and file_path.suffix == '.py':
                    issues.append({
                        'type': 'debug',
                        'file': str(rel_path),
                        'line': i,
                        'message': 'Posible debug print()'
                    })
            
        except Exception:
            pass
        
        return issues
    
    def _generate_suggestions(self, content: str, file_path: str) -> str:
        """Generar sugerencias usando LLM"""
        try:
            prompt = f"""Analiza este c√≥digo y proporciona sugerencias de mejora espec√≠ficas:

ARCHIVO: {file_path}

C√ìDIGO:
```
{content[:2000]}...
```

Proporciona sugerencias sobre:
1. Calidad del c√≥digo
2. Performance
3. Legibilidad
4. Buenas pr√°cticas
5. Posibles bugs

Responde de forma concisa y pr√°ctica."""

            messages = [{'role': 'user', 'content': prompt}]
            suggestions = self.ollama_interface.chat(messages, self.settings.models['primary'])
            
            if suggestions:
                return f"üí° **Sugerencias para '{file_path}':**\n\n{suggestions}"
            else:
                return f"üí° No se pudieron generar sugerencias para '{file_path}'"
                
        except Exception as e:
            return f"‚ùå Error generando sugerencias: {e}"
    
    def _detect_file_type(self, file_path: Path) -> str:
        """Detectar tipo de archivo"""
        suffix = file_path.suffix.lower()
        
        type_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.html': 'html',
            '.css': 'css',
            '.json': 'json',
            '.md': 'markdown',
            '.yml': 'yaml',
            '.yaml': 'yaml',
            '.toml': 'toml',
            '.txt': 'text'
        }
        
        return type_map.get(suffix, 'unknown')
    
    def _is_code_file(self, file_path: Path) -> bool:
        """Verificar si es un archivo de c√≥digo"""
        code_extensions = {'.py', '.js', '.ts', '.html', '.css', '.json', '.md', '.yml', '.yaml'}
        return file_path.suffix.lower() in code_extensions
    
    def _should_ignore_file(self, file_path: Path) -> bool:
        """Verificar si un archivo debe ser ignorado"""
        ignore_patterns = {'.git', '__pycache__', 'node_modules', '.vscode', '.idea'}
        
        for part in file_path.parts:
            if part in ignore_patterns or part.startswith('.'):
                return True
        
        return False
    
    def _format_size(self, size: int) -> str:
        """Formatear tama√±o"""
        if size < 1024:
            return f"{size}B"
        elif size < 1024 * 1024:
            return f"{size/1024:.1f}KB"
        else:
            return f"{size/(1024*1024):.1f}MB"
    
    def _format_languages(self, languages: Counter) -> str:
        """Formatear lista de lenguajes"""
        if not languages:
            return "No identificados"
        
        result = []
        for lang, count in languages.most_common(5):
            result.append(f"{lang} ({count})")
        
        return ", ".join(result)
    
    def _format_main_structure(self, files: List[Dict[str, Any]]) -> str:
        """Formatear estructura principal"""
        # Obtener directorios principales
        directories = set()
        for file_info in files:
            path_parts = Path(file_info['path']).parts
            if len(path_parts) > 1:
                directories.add(path_parts[0])
        
        return ", ".join(sorted(list(directories)[:8]))
    
    def get_cache_stats(self) -> str:
        """
        Obtener estad√≠sticas del sistema de cache
        
        Returns:
            Estad√≠sticas formateadas del cache
        """
        stats = self.cache.get_cache_stats()
        
        result = "üìä Estad√≠sticas del Cache de An√°lisis:\n\n"
        result += f"üìÅ Contenido de archivos cacheado: {stats['file_content_cache_size']}\n"
        result += f"üå≥ An√°lisis AST cacheado: {stats['ast_cache_size']}\n"
        result += f"ü§ñ An√°lisis LLM cacheado: {stats['analysis_cache_size']}\n"
        result += f"üìã Estructura de proyecto: {'‚úÖ Cacheada' if stats['project_structure_cached'] else '‚ùå No cacheada'}\n"
        result += f"üìè L√≠mite m√°ximo: {stats['max_cache_size']} entradas por cache\n\n"
        
        total_cached = stats['file_content_cache_size'] + stats['ast_cache_size'] + stats['analysis_cache_size']
        if total_cached > 0:
            result += f"üöÄ Total: {total_cached} elementos cacheados - acelera an√°lisis repetitivos"
        else:
            result += "üìù Cache vac√≠o - se poblar√° con el uso"
            
        return result
    
    def clear_analysis_cache(self) -> str:
        """
        Limpiar el cache de an√°lisis
        
        Returns:
            Mensaje de confirmaci√≥n
        """
        self.cache.clear_cache()
        return "üßπ Cache de an√°lisis limpiado - pr√≥ximos an√°lisis ser√°n recalculados"